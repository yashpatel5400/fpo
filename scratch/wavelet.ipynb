{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import argparse\n",
    "import scipy\n",
    "import torch\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pickle\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "import math\n",
    "\n",
    "from fno_utils import FNO2d, FNODatasetSingle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "\n",
    "cfg_fn = os.path.join(\"..\", \"experiments\", f\"config_rdb.yaml\")\n",
    "with open(cfg_fn, \"r\") as f:\n",
    "    cfg = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pde_name = cfg[\"filename\"].split(\".h\")[0]\n",
    "model_weights = torch.load(os.path.join(\"..\", \"experiments\", f\"{pde_name}_FNO.pt\"), map_location=torch.device('cuda'))\n",
    "\n",
    "fno = FNO2d(\n",
    "    num_channels=cfg[\"num_channels\"], \n",
    "    modes1=cfg[\"modes\"], \n",
    "    modes2=cfg[\"modes\"], \n",
    "    width=cfg[\"width\"], \n",
    "    initial_step=cfg[\"initial_step\"]).to(\"cuda\")\n",
    "fno.load_state_dict(model_weights[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".H5 file extension is assumed hereafter\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "downsampling = [1,2,4]\n",
    "for resolution in downsampling:\n",
    "    batch_size = 25\n",
    "    train_data = FNODatasetSingle(filename=os.path.join(\"..\", \"experiments\", cfg[\"filename\"]), reduced_resolution=resolution)\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size)\n",
    "\n",
    "    res_scores = []\n",
    "    for xxbatch, yy, gridbatch in train_loader:\n",
    "        if cfg[\"training_type\"] == \"autoregressive\":\n",
    "            inp_shape = list(xxbatch.shape)\n",
    "            inp_shape = inp_shape[:-2]\n",
    "            inp_shape.append(-1)\n",
    "\n",
    "            xxbatch = xxbatch.reshape(inp_shape)\n",
    "            yyhat   = fno(xxbatch.to(device), gridbatch.to(device))\n",
    "            yybatch = yy[:,:,:,10:11,:].to(device)\n",
    "        else:\n",
    "            xidx = 0\n",
    "            xx   = xxbatch[xidx:xidx+1,...].to(device)\n",
    "            grid = gridbatch[xidx:xidx+1,...].to(device)\n",
    "            yhat = fno(xx[...,0,:], grid)\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "fn = \"../results/regret_rdb-True.pkl\"\n",
    "with open(fn, \"rb\") as f:\n",
    "    regrets = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing parameters\n",
    "scale = 7\n",
    "dx    = pow(2, -scale)\n",
    "k_s   = 1. / sqrt(pow(2, scale))\n",
    "\n",
    "# Wavelet decomposition\n",
    "wavelet_family = \"db2\"\n",
    "wavelet = pywt.Wavelet(wavelet_family)\n",
    "fL, fH, x_wav = wavelet.wavefun(level=scale+2)\n",
    "\n",
    "A = 0.0105 # db2: ~0.0105\n",
    "B = wavelet.rec_len - 2\n",
    "\n",
    "def find_nearest(array, value):\n",
    "    idx = np.searchsorted(array, value, side=\"left\")\n",
    "    if idx > 0 and (idx == len(array) or math.fabs(value - array[idx-1]) < math.fabs(value - array[idx])):\n",
    "        return idx-1\n",
    "    return idx\n",
    "\n",
    "def get_disc_idxs(xi, ks, inv_s):\n",
    "    disc_xs = inv_s * xi - ks + B\n",
    "    idx_tmp = np.searchsorted(x_wav, disc_xs)\n",
    "    idxs = np.clip(idx_tmp - 1, 0, len(x_wav)-1)\n",
    "    return idxs\n",
    "\n",
    "def cartesian_product(*arrays):\n",
    "    la = len(arrays)\n",
    "    dtype = np.result_type(*arrays)\n",
    "    arr = np.empty([len(a) for a in arrays] + [la], dtype=dtype)\n",
    "    for i, a in enumerate(np.ix_(*arrays)):\n",
    "        arr[...,i] = a\n",
    "    return arr.reshape(-1, la)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = yyhat[0,...,0,0].cpu().detach().numpy()\n",
    "\n",
    "coeffs = pywt.dwt2(y, wavelet_family)\n",
    "nb_levels = len(coeffs) - 1\n",
    "\n",
    "LL, (LH, HL, HH) = coeffs\n",
    "coeffs = np.array([LL, LH, HL, HH]).reshape(-1)\n",
    "coeffs = np.expand_dims(np.expand_dims(coeffs, axis=-1), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_rec  = np.arange(0, 1, dx)\n",
    "x_grid = cartesian_product(x_rec, x_rec)\n",
    "x_grid_offset = np.expand_dims(np.expand_dims(x_grid - A, 1), 1)\n",
    "\n",
    "inv_s = pow(2, scale - nb_levels)\n",
    "ks    = np.array([[(k_1, k_2) for k_2 in range(LL.shape[1])] for k_1 in range(LL.shape[0])])\n",
    "idxs  = get_disc_idxs(x_grid_offset, ks, inv_s)\n",
    "\n",
    "final_shape_tuple = (x_rec.shape[0], x_rec.shape[0], -1)\n",
    "\n",
    "fL_x, fL_y = fL[idxs[...,0]].reshape(final_shape_tuple), fL[idxs[...,1]].reshape(final_shape_tuple)\n",
    "fH_x, fH_y = fH[idxs[...,0]].reshape(final_shape_tuple), fH[idxs[...,1]].reshape(final_shape_tuple)\n",
    "\n",
    "disc_fLL = (fL_x * fL_y).reshape(final_shape_tuple)\n",
    "disc_fLH = (fH_x * fL_y).reshape(final_shape_tuple)\n",
    "disc_fHL = (fL_x * fH_y).reshape(final_shape_tuple)\n",
    "disc_fHH = (fH_x * fH_y).reshape(final_shape_tuple)\n",
    "disc_f   = (k_s * sqrt(inv_s) / sqrt(2)) * np.concatenate([disc_fLL, disc_fLH, disc_fHL, disc_fHH], axis=-1)\n",
    "disc_f   = np.transpose(disc_f, axes=(2, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rec = np.sum(disc_f * coeffs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basin_integral(f, center, radius):\n",
    "    integral_mask = (np.linalg.norm(x_grid - center, axis=1) < radius).astype(np.int8).reshape(y_rec.shape)\n",
    "    return np.sum(f * integral_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "basin_center  = np.array([0.75, 0.6])\n",
    "basin_radius  = 0.2\n",
    "integral      = basin_integral(disc_f[0], basin_center, basin_radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "# yhat = yhat.reshape(1, -1)\n",
    "# y    = yybatch[0, ...,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = y - yhat\n",
    "diff = diff.reshape(diff.shape[0], -1).detach().cpu().numpy()\n",
    "# np.linalg.norm(diff.reshape(diff.shape[0], -1), ord=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "from wavelet import get_disc_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16384,)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = yyhat[0, ...,0,0].detach().cpu().numpy().flatten()\n",
    "w = np.array([0.6, 0.6])\n",
    "r = 0.05\n",
    "quantile = 1.0\n",
    "\n",
    "x_grid = get_disc_grid(128)\n",
    "w_mask = (np.linalg.norm(x_grid - w, axis=1) < r).astype(np.int8)\n",
    "\n",
    "u = cp.Variable(yhat.shape)\n",
    "\n",
    "objective = cp.Minimize(-u @ w_mask)\n",
    "constraints = [cp.norm(u - yhat) <= quantile]\n",
    "prob = cp.Problem(objective, constraints)\n",
    "obj  = prob.solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-153.77769533509266"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "operator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
